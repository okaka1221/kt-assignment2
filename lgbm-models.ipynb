{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import string\n",
    "import re\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/BEST&MOST200/train-best200.csv')\n",
    "dev = pd.read_csv('./data/BEST&MOST200/dev-best200.csv')\n",
    "test = pd.read_csv('./data/BEST&MOST200/test-best200.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (96585, 457)\n",
      "Dev shape  : (34028, 457)\n",
      "Test shape : (32977, 457)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape:', train.shape)\n",
    "print('Dev shape  :', dev.shape)\n",
    "print('Test shape :', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_same_user(df):\n",
    "    df_class = df[['user-id', 'class']].groupby('user-id').apply(lambda x: x['class'].mode()).reset_index()\n",
    "    df_class = df_class.rename(columns={0: 'class'})\n",
    "    df_new = df.groupby('user-id').sum().reset_index()\n",
    "    df_new = pd.merge(df_new, df_class, on='user-id')\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_per_user = merge_same_user(train)\n",
    "dev_per_user = merge_same_user(dev)\n",
    "\n",
    "train_per_user = pd.concat([train_per_user, dev_per_user], axis=0)\n",
    "test_per_user = merge_same_user(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train per user shape: (3190, 457)\n",
      "Test per user shape : (802, 457)\n"
     ]
    }
   ],
   "source": [
    "print('Train per user shape:', train_per_user.shape)\n",
    "print('Test per user shape :', test_per_user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data, pred):\n",
    "    y_true = data\n",
    "    reshaped_pred = pred.reshape(3, len(pred) // 3)\n",
    "    y_pred = np.argmax(reshaped_pred, axis=0)\n",
    "    acc = np.mean(y_true == y_pred)\n",
    "    return 'accuracy', acc, True\n",
    "\n",
    "def train_model(X, y, X_test, params, fold_num):\n",
    "    result_dict = {}\n",
    "    oof = np.zeros((len(X), 3))\n",
    "    prediction = np.zeros((len(X_test), 3))\n",
    "    scores = []\n",
    "    features = X.columns\n",
    "    feature_importance = pd.DataFrame()\n",
    "\n",
    "    folds = StratifiedKFold(n_splits=fold_num)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(folds.split(X, y)):\n",
    "        print(f'\\nFold {fold + 1} started at {time.ctime()}')\n",
    "        \n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y[train_idx], y[val_idx]\n",
    "        \n",
    "        model = lgb.LGBMClassifier(\n",
    "            **params,\n",
    "            )\n",
    "        \n",
    "        model.fit(X_train, y_train,\n",
    "                  eval_set=[(X_val, y_val)],\n",
    "                  eval_metric=accuracy,\n",
    "                  verbose=False,\n",
    "                  early_stopping_rounds=100)\n",
    "        \n",
    "        y_pred_val_proba = model.predict_proba(X_val)\n",
    "        y_pred_val = model.predict(X_val)\n",
    "        y_pred_proba = model.predict_proba(X_test)\n",
    "        \n",
    "        accuracy_val = accuracy_score(y_val, y_pred_val)\n",
    "        scores.append(accuracy_val)\n",
    "        \n",
    "        print('\\nFold {0: d} accuracy: {1: .4f}'.format(fold + 1, accuracy_val))\n",
    "        \n",
    "        oof[val_idx] += y_pred_val_proba.reshape(-1, 3)\n",
    "        prediction += y_pred_proba / fold_num\n",
    "        \n",
    "        fold_importance = pd.DataFrame()\n",
    "        fold_importance['feature'] = features\n",
    "        fold_importance['importance'] = model.feature_importances_\n",
    "        fold_importance['fold'] = fold + 1\n",
    "        feature_importance = pd.concat([feature_importance, fold_importance], axis=0)\n",
    "        \n",
    "    print('\\nCV mean accuracy {0: .4f}'.format(np.mean(scores)))\n",
    "    \n",
    "    cols = feature_importance[['feature', 'importance']].groupby('feature').mean().sort_values(by='importance', ascending=False).index\n",
    "    best_features = feature_importance[['feature', 'importance']].groupby('feature').mean().sort_values(by='importance', ascending=False).reset_index()\n",
    "\n",
    "    result_dict['oof'] = oof\n",
    "    result_dict['prediction'] = prediction\n",
    "    result_dict['scores'] = scores\n",
    "    result_dict['feature_importance'] = best_features\n",
    "    \n",
    "#     plt.figure(figsize=(16,128))\n",
    "#     sns.barplot(x='importance', y='feature', data=best_features)\n",
    "#     plt.title('LGB Features (avg over folds)')\n",
    "        \n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 started at Fri Oct 11 17:41:51 2019\n",
      "\n",
      "Fold  1 accuracy:  0.8224\n",
      "\n",
      "Fold 2 started at Fri Oct 11 17:42:02 2019\n",
      "\n",
      "Fold  2 accuracy:  0.8193\n",
      "\n",
      "Fold 3 started at Fri Oct 11 17:42:11 2019\n",
      "\n",
      "Fold  3 accuracy:  0.8219\n",
      "\n",
      "Fold 4 started at Fri Oct 11 17:42:22 2019\n",
      "\n",
      "Fold  4 accuracy:  0.8281\n",
      "\n",
      "Fold 5 started at Fri Oct 11 17:42:33 2019\n",
      "\n",
      "Fold  5 accuracy:  0.8019\n",
      "\n",
      "Fold 6 started at Fri Oct 11 17:42:44 2019\n",
      "\n",
      "Fold  6 accuracy:  0.8365\n",
      "\n",
      "Fold 7 started at Fri Oct 11 17:42:54 2019\n",
      "\n",
      "Fold  7 accuracy:  0.8239\n",
      "\n",
      "Fold 8 started at Fri Oct 11 17:43:07 2019\n",
      "\n",
      "Fold  8 accuracy:  0.8176\n",
      "\n",
      "Fold 9 started at Fri Oct 11 17:43:18 2019\n",
      "\n",
      "Fold  9 accuracy:  0.8396\n",
      "\n",
      "Fold 10 started at Fri Oct 11 17:43:24 2019\n",
      "\n",
      "Fold  10 accuracy:  0.8365\n",
      "\n",
      "CV mean accuracy  0.8248\n"
     ]
    }
   ],
   "source": [
    "X = train_per_user.drop(['tweet-id', 'user-id', 'class'], axis=1)\n",
    "X_test = test_per_user.drop(['tweet-id', 'user-id', 'class'], axis=1)\n",
    "\n",
    "y = train_per_user['class']\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 5000,\n",
    "}\n",
    "\n",
    "result_dict = train_model(X, y, X_test, params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8247648902821316"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = train_per_user[['user-id', 'class']]\n",
    "validation['prediction'] = encoder.inverse_transform(np.argmax(result_dict['oof'], axis=1))\n",
    "validation[encoder.classes_[0]] = result_dict['oof'][:, 0]\n",
    "validation[encoder.classes_[1]] = result_dict['oof'][:, 1]\n",
    "validation[encoder.classes_[2]] = result_dict['oof'][:, 2]\n",
    "validation.to_csv('./result-per-user/lgbm-val.csv', index=False)\n",
    "accuracy_score(validation['class'], validation['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_per_user[['user-id', 'class']]\n",
    "submission['prediction'] = encoder.inverse_transform(np.argmax(result_dict['prediction'], axis=1))\n",
    "submission[encoder.classes_[0]] = result_dict['prediction'][:, 0]\n",
    "submission[encoder.classes_[1]] = result_dict['prediction'][:, 1]\n",
    "submission[encoder.classes_[2]] = result_dict['prediction'][:, 2]\n",
    "submission.to_csv('./result-per-user/lgbm-test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_cols = ['aha', 'ahah', 'ahaha', 'ahahah', 'ahahaha', 'ahahahaha', 'bahaha', 'bahahaha', 'haha', 'hahah', 'hahaha', 'hahahah', 'hahahaha', 'hahahahaha', 'hahahahahaha']\n",
    "\n",
    "for w in stop_words:\n",
    "    if w in train.columns:\n",
    "        remove_cols.append(w)\n",
    "        \n",
    "train_per_user = train_per_user.drop(remove_cols, axis=1)\n",
    "test_per_user = test_per_user.drop(remove_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train per user shape: (3190, 401)\n",
      "Test per user shape : (802, 401)\n"
     ]
    }
   ],
   "source": [
    "print('Train per user shape:', train_per_user.shape)\n",
    "print('Test per user shape :', test_per_user.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1 started at Fri Oct 11 17:43:37 2019\n",
      "\n",
      "Fold  1 accuracy:  0.8224\n",
      "\n",
      "Fold 2 started at Fri Oct 11 17:43:43 2019\n",
      "\n",
      "Fold  2 accuracy:  0.8193\n",
      "\n",
      "Fold 3 started at Fri Oct 11 17:43:49 2019\n",
      "\n",
      "Fold  3 accuracy:  0.8219\n",
      "\n",
      "Fold 4 started at Fri Oct 11 17:43:54 2019\n",
      "\n",
      "Fold  4 accuracy:  0.8063\n",
      "\n",
      "Fold 5 started at Fri Oct 11 17:44:02 2019\n",
      "\n",
      "Fold  5 accuracy:  0.7956\n",
      "\n",
      "Fold 6 started at Fri Oct 11 17:44:09 2019\n",
      "\n",
      "Fold  6 accuracy:  0.8270\n",
      "\n",
      "Fold 7 started at Fri Oct 11 17:44:15 2019\n",
      "\n",
      "Fold  7 accuracy:  0.8208\n",
      "\n",
      "Fold 8 started at Fri Oct 11 17:44:23 2019\n",
      "\n",
      "Fold  8 accuracy:  0.8082\n",
      "\n",
      "Fold 9 started at Fri Oct 11 17:44:33 2019\n",
      "\n",
      "Fold  9 accuracy:  0.8113\n",
      "\n",
      "Fold 10 started at Fri Oct 11 17:44:41 2019\n",
      "\n",
      "Fold  10 accuracy:  0.7987\n",
      "\n",
      "CV mean accuracy  0.8132\n"
     ]
    }
   ],
   "source": [
    "X = train_per_user.drop(['tweet-id', 'user-id', 'class'], axis=1)\n",
    "X_test = test_per_user.drop(['tweet-id', 'user-id', 'class'], axis=1)\n",
    "\n",
    "y = train_per_user['class']\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "params = {\n",
    "    'n_estimators': 5000,\n",
    "}\n",
    "\n",
    "result_dict = train_model(X, y, X_test, params, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8131661442006269"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation = train_per_user[['user-id', 'class']]\n",
    "validation['prediction'] = encoder.inverse_transform(np.argmax(result_dict['oof'], axis=1))\n",
    "validation[encoder.classes_[0]] = result_dict['oof'][:, 0]\n",
    "validation[encoder.classes_[1]] = result_dict['oof'][:, 1]\n",
    "validation[encoder.classes_[2]] = result_dict['oof'][:, 2]\n",
    "validation.to_csv('./result-per-user/lgbm-remove-stopwords-val.csv', index=False)\n",
    "accuracy_score(validation['class'], validation['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_per_user[['user-id', 'class']]\n",
    "submission['prediction'] = encoder.inverse_transform(np.argmax(result_dict['prediction'], axis=1))\n",
    "submission[encoder.classes_[0]] = result_dict['prediction'][:, 0]\n",
    "submission[encoder.classes_[1]] = result_dict['prediction'][:, 1]\n",
    "submission[encoder.classes_[2]] = result_dict['prediction'][:, 2]\n",
    "submission.to_csv('./result-per-user/lgbm-remove-stopwords-test.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
