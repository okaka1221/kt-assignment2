{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm import tqdm\n",
    "import operator\n",
    "import gc\n",
    "import time\n",
    "\n",
    "import nltk\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "import string\n",
    "import re\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('./data/train_tweets.csv')\n",
    "dev = pd.read_csv('./data/dev_tweets.csv')\n",
    "test = pd.read_csv('./data/test_tweets.csv')\n",
    "\n",
    "train['tweet'] = train['tweet'].astype(str)\n",
    "dev['tweet'] = dev['tweet'].astype(str)\n",
    "test['tweet'] = test['tweet'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (96585, 4)\n",
      "Dev shape  : (34028, 4)\n",
      "Test shape : (32977, 4)\n"
     ]
    }
   ],
   "source": [
    "print('Train shape:', train.shape)\n",
    "print('Dev shape  :', dev.shape)\n",
    "print('Test shape :', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contraction_mapping = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\",  \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\",  \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\",\"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\" }\n",
    "\n",
    "def clean_contractions(text, mapping):\n",
    "    specials = [\"’\", \"‘\", \"´\", \"`\"]\n",
    "    for special in specials:\n",
    "        text = text.replace(special, \"'\")\n",
    "    text = ' '.join([mapping[t] if t in mapping else t for t in text.split(' ')])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove '@USER_*****'\n",
    "train['tweet'] = train['tweet'].apply(lambda x: ' '.join([word for word in x.split(' ') if word[0:6] != '@USER_']))\n",
    "dev['tweet'] = dev['tweet'].apply(lambda x: ' '.join([word for word in x.split(' ') if word[0:6] != '@USER_']))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: ' '.join([word for word in x.split(' ') if word[0:6] != '@USER_']))\n",
    "\n",
    "# clean contruction\n",
    "train['tweet'] = train['tweet'].apply(lambda x: clean_contractions(x, contraction_mapping))\n",
    "dev['tweet'] = dev['tweet'].apply(lambda x: clean_contractions(x, contraction_mapping))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: clean_contractions(x, contraction_mapping))\n",
    "\n",
    "# lower text\n",
    "train['tweet'] = train['tweet'].apply(lambda x: x.lower())\n",
    "dev['tweet'] = dev['tweet'].apply(lambda x: x.lower())\n",
    "test['tweet'] = test['tweet'].apply(lambda x: x.lower())\n",
    "\n",
    "# remove stop words\n",
    "train['tweet'] = train['tweet'].apply(lambda x: ' '.join([word for word in x.split(' ') if word not in stopwords]))\n",
    "dev['tweet'] = dev['tweet'].apply(lambda x: ' '.join([word for word in x.split(' ') if word not in stopwords]))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: ' '.join([word for word in x.split(' ') if word not in stopwords]))\n",
    "\n",
    "# remove non alphabetic chars\n",
    "train['tweet'] = train['tweet'].apply(lambda x: re.sub('[^a-z]+', ' ', x))\n",
    "dev['tweet'] = dev['tweet'].apply(lambda x: re.sub('[^a-z]+', ' ', x))\n",
    "test['tweet'] = test['tweet'].apply(lambda x: re.sub('[^a-z]+', ' ', x))\n",
    "\n",
    "# strip text\n",
    "train['tweet'] = train['tweet'].apply(lambda x: x.strip())\n",
    "dev['tweet'] = dev['tweet'].apply(lambda x: x.strip())\n",
    "test['tweet'] = test['tweet'].apply(lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_same_user(df):\n",
    "    df_class = df[['user-id', 'class']].groupby('user-id').apply(lambda x: x['class'].mode()).reset_index()\n",
    "    df_class = df_class.rename(columns={0: 'class'})\n",
    "    df_new = df[['user-id', 'tweet']].groupby('user-id').agg(lambda x: ' '.join(x))\n",
    "    df_new = pd.merge(df_new, df_class, on='user-id')\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_per_user = merge_same_user(train)\n",
    "dev_per_user = merge_same_user(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([train_per_user, dev_per_user], axis=0)\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=20000)\n",
    "vectorizer.fit(merged['tweet'])\n",
    "\n",
    "merged_vec = vectorizer.transform(merged['tweet'])\n",
    "merged_vec = pd.DataFrame(merged_vec.todense(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi_selector = SelectKBest(chi2, k=500)\n",
    "chi_selector.fit(merged_vec, merged['class'])\n",
    "chi_columns = merged_vec.columns[chi_selector.get_support()]\n",
    "\n",
    "mi_selector = SelectKBest(mutual_info_classif, k=500)\n",
    "mi_selector.fit(merged_vec, merged['class'])\n",
    "mi_columns = merged_vec.columns[mi_selector.get_support()]\n",
    "\n",
    "all_columns = chi_columns\n",
    "all_columns = all_columns.append(mi_columns)\n",
    "all_columns = np.array(all_columns, dtype=str)\n",
    "all_columns = np.unique(all_columns)\n",
    "np.save('best500', all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "975"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
